References
Chen, Tianqi, Li, Mu, Li, Yutian, Lin, Min, Wang, Naiyan, Wang, Minjie, Xiao, Tianjun, Xu, Bing, Zhang, Chiyuan, and Zhang, Zheng.
Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems.
arXiv preprint arXiv:1512.01274, 2015.

Cohen, Nadav and Shashua, Amnon.
Convolutional rectifier networks as generalized tensor decompositions.
arXiv preprint arXiv:1603.00162, 2016.

Cohen, Nadav, Sharir, Or, and Shashua, Amnon.
Deep simnets.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 4782–4791, 2016.

De Lathauwer, Lieven.
Decompositions of a higher-order tensor in block terms–part ii: Definitions and uniqueness.
SIAM Journal on Matrix Analysis and Applications, 30(3):1033–34, 2008.

Eigen, David, Rolfe, Jason, Fergus, Rob, and LeCun, Yann.
Understanding deep architectures using a recursive convolutional network.
arXiv preprint arXiv:1312.1847, 2013.

Garipov, Timur, Podoprikhin, Dmitry, Novikov, Alexander, and Vetrov, Dmitry.
Ultimate tensorization: compressing convolutional and fc layers alike.
arXiv preprint arXiv:1611.03214, 2016.

Ha, David, Dai, Andrew, and Le, Quoc V.
Hypernetworks.
arXiv preprint arXiv:1609.09106, 2016.

He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian.
Deep residual learning for image recognition.
In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 770–778, 2016a.

He, Kaiming, Zhang, Xiangyu, Ren, Shaoqing, and Sun, Jian.
Identity mappings in deep residual networks.
In European Conference on Computer Vision, pp. 630–645.
Springer, 2016b.

Ioffe, Sergey and Szegedy, Christian.
Batch normalization: Accelerating deep network training by reducing internal covariate shift.
arXiv preprint arXiv:1502.03167, 2015.

Jaderberg, Max, Vedaldi, Andrea, and Zisserman, Andrew.
Speeding up convolutional neural networks with low rank expansions.
arXiv preprint arXiv:1405.3866, 2014.

Kingma, Diederik and Ba, Jimmy.
Adam: A method for stochastic optimization.
arXiv preprint arXiv:1412.6980, 2014.

Kolda, Tamara G and Bader, Brett W.
Tensor decompositions and applications.
SIAM review, 51(3):455–500, 2009.

Krizhevsky, Alex.
Learning multiple layers of features from tiny images.
2009.

Lebedev, Vadim, Ganin, Yaroslav, Rakhuba, Maksim, Oseledets, Ivan, and Lempitsky, Victor.
Speedingup convolutional neural networks using fine-tuned cpdecomposition.
arXiv preprint arXiv:1412.6553, 2014.

Li, Yi, He, Kaiming, Sun, Jian, et al.
R-fcn: Object detection via region-based fully convolutional networks.
In Advances in Neural Information Processing Systems, pp. 379–387, 2016.

Liao, Qianli and Poggio, Tomaso.
Bridging the gaps between residual learning, recurrent neural networks and visual cortex.
arXiv preprint arXiv:1604.03640, 2016.

Novikov, Alexander, Podoprikhin, Dmitrii, Osokin, Anton, and Vetrov, Dmitry P.
Tensorizing neural networks.
In Advances in Neural Information Processing Systems, pp. 442–450, 2015.

Oseledets, Ivan V.
Tensor-train decomposition.
SIAM Journal on Scientific Computing, 33(5):2295–2317, 2011.

Russakovsky, Olga, Deng, Jia, Su, Hao, Krause, Jonathan, Satheesh, Sanjeev, Ma, Sean, Huang, Zhiheng, Karpathy, Andrej, Khosla, Aditya, Bernstein, Michael, Berg, Alexander C., and Fei-Fei, Li.
ImageNet Large Scale Visual Recognition Challenge.
International Journal of Computer Vision (IJCV), 115(3):211–252, 2015. doi: 10. 1007/s11263-015-0816-y.

Szegedy, Christian, Ioffe, Sergey, Vanhoucke, Vincent, and Alemi, Alex.
Inception-v4, inception-resnet and the impact of residual connections on learning.
arXiv preprint arXiv:1602.07261, 2016.

Tucker, Ledyard R.
Some mathematical notes on threemode factor analysis.
Psychometrika, 31(3):279–311, 1966.

Veit, Andreas, Wilber, Michael J, and Belongie, Serge.
Residual networks behave like ensembles of relatively shallow networks.
In Advances in Neural Information Processing Systems, pp. 550–558, 2016.

Wu, Zifeng, Shen, Chunhua, and Hengel, Anton van den.
Wider or deeper: Revisiting the resnet model for visual recognition.
arXiv preprint arXiv:1611.10080, 2016.

Xie, Saining, Girshick, Ross, Dollar, Piotr, Tu, Zhuowen, ´ and He, Kaiming.
Aggregated residual transformations for deep neural networks.
arXiv preprint arXiv:1611.05431, 2016.

Zagoruyko, Sergey and Komodakis, Nikos.
Wide residual networks.
arXiv preprint arXiv:1605.07146, 2016.

Zhang, Xingcheng, Li, Zhizhong, Loy, Chen Change, and Lin, Dahua.
Polynet: A pursuit of structural diversity in very deep networks.
arXiv preprint arXiv:1611.05725, 2016.

Zhao, Hengshuang, Shi, Jianping, Qi, Xiaojuan, Wang, Xiaogang, and Jia, Jiaya.
Pyramid scene parsing network.
arXiv preprint arXiv:1612.01105, 2016.

Zhou, Bolei, Khosla, Aditya, Lapedriza, Agata, Torralba, Antonio, and Oliva, Aude.
Places: An image database for deep scene understanding.
arXiv preprint arXiv:1610.02055, 2016.
