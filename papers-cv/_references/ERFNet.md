REFERENCES
[1] E. Romera, L. M. Bergasa, and R. Arroyo. (Jul. 2016). “Can we unify monocular detectors for autonomous driving by using the pixel-wise semantic segmentation of CNNs?” [Online]. Available: https://arxiv.org/abs/1607.00971
[2] X. He, R. S. Zemel, and M. Á. Carreira-Perpiñán, “Multiscale conditional random fields for image labeling,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), vol. 2. Jun. 2004, pp. II-695–II-702.
[3] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning applied to document recognition,” Proc. IEEE, vol. 86, no. 11, pp. 2278–2324, Nov. 1998.
[4] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “ImageNet classification with deep convolutional neural networks,” in Advances in Neural Information Processing Systems, vol. 25, F. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, Eds. South Lake Tahoe, NV, USA: Curran Associates, 2012, pp. 1097–1105. [Online]. Available: http://papers.nips.cc/paper/4824-imagenet-classification-withdeep-convolutional-neural-networks.pdf
[5] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for semantic segmentation,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2015, pp. 3431–3440.
[6] K. He, X. Zhang, S. Ren, and J. Sun. (Dec. 2015). “Deep residual learning for image recognition.” [Online]. Available: https://arxiv. org/abs/1512.03385
[7] S. Zagoruyko and N. Komodakis. (May 2016). “Wide residual networks.” [Online]. Available: https://arxiv.org/abs/1605.07146
[8] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. (Jun. 2016). “DeepLab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs.” [Online]. Available: https://arxiv.org/abs/1606.00915
[9] G. Lin, A. Milan, C. Shen, and I. Reid. (Nov. 2016). “RefineNet: Multi-path refinement networks for high-resolution semantic segmentation.” [Online]. Available: https://arxiv.org/abs/1611.06612
[10] T. Pohlen, A. Hermans, M. Mathias, and B. Leibe. (Nov. 2016). “Full-resolution residual networks for semantic segmentation in street scenes.” [Online]. Available: https://arxiv.org/abs/1611.08323
[11] A. Paszke, A. Chaurasia, S. Kim, and E. Culurciello. (Jun. 2016). “ENet: A deep neural network architecture for real-time semantic segmentation.” [Online]. Available: https://arxiv.org/abs/1606.02147
[12] M. Treml, J. Arjona-Medina, T. Unterthiner, and, “Speeding up semantic segmentation for autonomous driving,” in Proc. MLITS, NIPS Workshop, 2016, p. 8.
[13] M. Cordts et al., “The cityscapes dataset for semantic urban scene understanding,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 3213–3223.
[14] E. Romera, J. M. Álvarez, L. M. Bergasa, and R. Arroyo, “Efficient ConvNet for real-time semantic segmentation,” in Proc. IEEE Intell. Veh. Symp. (IV), Jun. 2017, pp. 1789–1794.
[15] K. Simonyan and A. Zisserman. (Sep. 2014). “Very deep convolutional networks for large-scale image recognition.” [Online]. Available: https://arxiv.org/abs/1409.1556
[16] V. Badrinarayanan, A. Handa, and R. Cipolla. (May 2015). “SegNet: A deep convolutional encoder-decoder architecture for robust semantic pixel-wise labelling.” [Online]. Available: https:// arxiv.org/abs/1505.07293
[17] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. (Dec. 2014). “Semantic image segmentation with deep convolutional nets and fully connected CRFs.” [Online]. Available: https:// arxiv.org/abs/1412.7062
[18] S. Zheng et al., “Conditional random fields as recurrent neural networks,” in Proc. IEEE Int. Conf. Comput. Vis. (ICCV), Dec. 2015, pp. 1529–1537.
[19] G. Ghiasi and C. C. Fowlkes, “Laplacian pyramid reconstruction and refinement for semantic segmentation,” in Proc. Eur. Conf. Comput. Vis. (ECCV), 2016, pp. 519–534.
[20] Z. Wu, C. Shen, and A. van den Hengel. (Apr. 2016). “High-performance semantic segmentation using very deep fully convolutional networks.” [Online]. Available: https://arxiv.org/abs/1604.04339
[21] M. Rastegari, V. Ordonez, J. Redmon, and A. Farhadi. (Mar. 2016). “XNOR-net: ImageNet classification using binary convolutional neural networks.” [Online]. Available: https://arxiv.org/abs/1603.05279
[22] J. Alvarez and L. Petersson. (Jun. 2016). “DecomposeMe: Simplifying ConvNets for end-to-end learning.” [Online]. Available: https://arxiv. org/abs/1606.05426
[23] M. Jaderberg, A. Vedaldi, and A. Zisserman. (May 2014). “Speeding up convolutional neural networks with low rank expansions.” [Online]. Available: https://arxiv.org/abs/1405.3866
[24] R. Rigamonti, A. Sironi, V. Lepetit, and P. Fua, “Learning separable filters,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., Jun. 2013, pp. 2754–2761.
[25] K. He, X. Zhang, S. Ren, and J. Sun, “Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification,” in Proc. IEEE Int. Conf. Comput. Vis., Dec. 2015, pp. 1026–1034.
[26] S. Jégou, M. Drozdzal, D. Vazquez, A. Romero, and Y. Bengio. (Nov. 2016). “The one hundred layers tiramisu: Fully convolutional DenseNets for semantic segmentation.” [Online]. Available: https://arxiv. org/abs/1611.09326
[27] F. Yu and V. Koltun. (Nov. 2015). “Multi-scale context aggregation by dilated convolutions.” [Online]. Available: https://arxiv.org/abs/ 1511.07122
[28] G. E. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. (Jul. 2012). “Improving neural networks by preventing co-adaptation of feature detectors.” [Online]. Available: https://arxiv.org/abs/1207.0580
[29] R. Collobert, K. Kavukcuoglu, and C. Farabet, “Torch7: A matlab-like environment for machine learning,” in Proc. BigLearn, NIPS Workshop, 2011, pp. 1–6.
[30] D. Kingma and J. Ba. (Dec. 2014). “Adam: A method for stochastic optimization.” [Online]. Available: https://arxiv.org/abs/1412.6980
[31] O. Russakovsky et al., “ImageNet large scale visual recognition challenge,” Int. J. Comput. Vis., vol. 115, no. 3, pp. 211–252, Dec. 2015.
[32] J. Yosinski, J. Clune, Y. Bengio, and H. Lipson, “How transferable are features in deep neural networks?” in Adv. Neural Inf. Process. Syst., 2014, pp. 3320–3328.
[33] G. Lin, C. Shen, A. Hengel, and I. Reid, “Efficient piecewise training of deep structured models for semantic segmentation,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 3194–3203.
[34] Z. Liu, X. Li, P. Luo, C.-C. Loy, and X. Tang, “Semantic image segmentation via deep parsing network,” in Proc. IEEE Int. Conf. Comput. Vis., Jun. 2015, pp. 1377–1385.
[35] I. Krešo, D. Cauševi´ ˇ c, J. Krapac, and S. Šegvi´c, “Convolutional scale invariance for semantic segmentation,” in Proc. German Conf. Pattern Recognit. (GCPR), 2016, pp. 64–75.
[36] J. Uhrig, M. Cordts, U. Franke, and T. Brox. (Apr. 2016). “Pixel-level encoding and depth layering for instance-level semantic labeling.” [Online]. Available: https://arxiv.org/abs/1604.05096
[37] G. Papandreou, L.-C. Chen, K. Murphy, and A. L. Yuille. (Feb. 2015). “Weakly- and semi-supervised learning of a DCNN for semantic image segmentation.” [Online]. Available: https://arxiv.org/abs/1502.02734
[38] G. Ros, L. Sellart, J. Materzynska, D. Vazquez, and A. M. Lopez, “The SYNTHIA dataset: A large collection of synthetic images for semantic segmentation of urban scenes,” in Proc. IEEE Conf. Comput. Vis. Pattern Recognit. (CVPR), Jun. 2016, pp. 3234–3243.
