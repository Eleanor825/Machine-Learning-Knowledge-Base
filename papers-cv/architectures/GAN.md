<span style="font-family:monospace">

# Papers in Computer Vision - GAN

count: 3

* (12 Dec 2018) [StyleGAN](https://arxiv.org/abs/1812.04948) (A Style-Based Generator Architecture for Generative Adversarial Networks)
* (03 Dec 2019) [StyleGAN2](https://arxiv.org/abs/1912.04958) (Analyzing and Improving the Image Quality of StyleGAN)
* (24 Mar 2022) [DualStyleGAN](https://arxiv.org/abs/2203.13248) (Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer)

* [Generative Multiplane Images: Making a 2D GAN 3D-Aware](https://arxiv.org/abs/2207.10642)
    * Title: Generative Multiplane Images: Making a 2D GAN 3D-Aware
    * Year: 21 Jul `2022`
    * Author: Xiaoming Zhao
    * Abstract: What is really needed to make an existing 2D GAN 3D-aware? To answer this question, we modify a classical GAN, i.e., StyleGANv2, as little as possible. We find that only two modifications are absolutely necessary: 1) a multiplane image style generator branch which produces a set of alpha maps conditioned on their depth; 2) a pose-conditioned discriminator. We refer to the generated output as a 'generative multiplane image' (GMPI) and emphasize that its renderings are not only high-quality but also guaranteed to be view-consistent, which makes GMPIs different from many prior works. Importantly, the number of alpha maps can be dynamically adjusted and can differ between training and inference, alleviating memory concerns and enabling fast training of GMPIs in less than half a day at a resolution of $1024^{2}$. Our findings are consistent across three challenging and common high-resolution datasets, including FFHQ, AFHQv2, and MetFaces.
* [A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics](https://arxiv.org/abs/2207.12599)
    * Title: A Survey of Explainable Graph Neural Networks: Taxonomy and Evaluation Metrics
    * Year: 26 Jul `2022`
    * Author: Yiqiao Li
    * Abstract: Graph neural networks (GNNs) have demonstrated a significant boost in prediction performance on graph data. At the same time, the predictions made by these models are often hard to interpret. In that regard, many efforts have been made to explain the prediction mechanisms of these models from perspectives such as GNNExplainer, XGNN and PGExplainer. Although such works present systematic frameworks to interpret GNNs, a holistic review for explainable GNNs is unavailable. In this survey, we present a comprehensive review of explainability techniques developed for GNNs. We focus on explainable graph neural networks and categorize them based on the use of explainable methods. We further provide the common performance metrics for GNNs explanations and point out several future research directions.
