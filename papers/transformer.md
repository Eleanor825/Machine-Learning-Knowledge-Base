<span style="font-family:monospace">

# Papers in Computer Vision - Transformer

count: 9

* [Transformer](https://arxiv.org/abs/1706.03762)
    * Title: Attention Is All You Need
    * Year: 12 Jun 2017
    * Author: Ashish Vaswani
* [Stand-Alone Self-Attention](https://arxiv.org/abs/1906.05909)
    * Title: Stand-Alone Self-Attention in Vision Models
    * Year: 13 Jun 2019
    * Author: Prajit Ramachandran
* [DETR](https://arxiv.org/abs/2005.12872)
    * Title: End-to-End Object Detection with Transformers
    * Year: 26 May 2020
* [Deformable DETR](https://arxiv.org/abs/2010.04159)
    * Title: Deformable DETR: Deformable Transformers for End-to-End Object Detection
    * Year: 08 Oct 2020
* [Vision Transformer](https://arxiv.org/abs/2010.11929)
    * Title: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale
    * Year: 22 Oct 2020
* [SETR](https://arxiv.org/abs/2012.15840)
    * Title: Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers
    * Year: 31 Dec 2020
* [Swin Transformer](https://arxiv.org/abs/2103.14030)
    * Title: Hierarchical Vision Transformer using Shifted Windows
    * Year: 25 Mar 2021
* [Swin Transformer V2](https://arxiv.org/abs/2111.09883)
    * Title: Scaling Up Capacity and Resolution
    * Year: 18 Nov 2021
* [Dynamic Head](https://arxiv.org/abs/2106.08322)
    * Title: Unifying Object Detection Heads with Attentions
    * Year: 15 Jun 2021
* [Fastformer](https://arxiv.org/abs/2108.09084)
    * Title: Fastformer: Additive Attention Can Be All You Need
    * Year: 20 Aug 2021
